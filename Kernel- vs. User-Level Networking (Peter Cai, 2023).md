"Recent literature often attest to significant performance gains arising from user-level networking in comparison to using the kernel network stack. However, abandoning the kernel network stack and instead re-implementing it at the user level often implies severe limitations on how the application is designed and deployed. For example, some user-level network stacks restrict the use of multi-threading, and most of them require dedicated network and CPU resources to function, at least to some extent. A study on exactly which elements of user-level networking bring about the claimed performance increase would be beneficial in balancing the advantages against limitations of user-level networking"

"two main aspects of user-level networking can be identified that improve performance, in contrast to kernel network stacks in their default configuration: 

1. Customization: The reduced functionality of some user-level stacks directly leads to a corresponding reduction in memory footprint and processing overhead. The removal of security-related system overheads (kernel-to-user memory copies, security checks, etc.), as an indirect result of customization, also contributes to a performance gain.
1. Alignment: Current user-level network stacks cannot directly receive hardware interrupts and thus use polling to interact with the Network Interface Controller (NIC). This leads to both spatial (core locality) and temporal (application-managed synchronous polling) alignment of network- and application-level processing, both of which are known to improve performance."

"The main conjecture of this work is that better alignment of network- and applicationlevel processing is possible without requiring massive changes or additions to a vanilla Linux system using the regular kernel network stack. It is shown that several simple configuration changes can bring the performance of the Linux kernel network stack much closer to user-level counterparts1 . However, these configurations on an unchanged kernel often involve significant caveats similar to user-level networking. The core result of this work is a small kernel modification with around 30 lines of code change that replaces these restrictive configuration schemes, enabling the kernel network stack to simulate the execution model of many user-level network stacks. This code change is demonstrated to achieve a significantly higher throughput without compromising tail latency, and without many of the restrictions associated with user-level networking and/or a manually optimized kernel network stack through configurations. An up to 45% performance increase can be observed with the aforementioned modification compared to a vanilla Linux kernel."

"Traditionally, most of the network protocol stack resides inside the operating system kernel as part of the basic infrastructure it provides to applications. The kernel typically ingests memory-mapped buffers of network data from the NIC after receiving a notification via an Interrupt Request (IRQ). Then, it passes these buffers through the link (Ethernet), network (IP), and transport (TCP, UDP, etc.) protocol layers. The buffers ultimately become part of a queue called socket buffer (one per transport instance), from which the data is made available to applications through standard system calls (read, write, etc.)."

With the increase in link transmission speeds and NIC capabilities kernels like Linux have also been improving their network stack to catch up/benefit w hardware. These improvements include reducing data copying and avoiding interrupts, scaling tx and rx queues to multiple processor cores, efforts to optimize communication and cooperation between kernels and applications. Early applications rely solely on blocking-based I/O system calls to synchronize with the kernel network stack under a thread per connection model placing enormous pressure on kernel's scheduler.
Later operating systems started to introduce I/O multiplexing based on select,poll and their successors *epoll* (Linux) / *kqueue* (BSD), enabling one application thread to operate on a much larger set of File Descriptors, removing this bottleneck. 
The more recent *io_uring* interface attempts to further reduce overhead by allowing the kernel and the application to communicate I/O events and requests using a ring buffer, shared directly between the address spaces of the kernel and the application. While its potential for high performance is sometimes eclipsed by its lack of optimization and backwards compatibility, its maturity, if achieved, could mean a significant performance boost for kernel networking.

"Nevertheless, the network processing path inside the Linux kernel involves a large amount of asynchronous notification delivery, even after the aforementioned attempts at streamlining the network stack. This complexity is in part due to the need for the kernel to remain generic and agnostic of application behaviour. Even though the kernel attempts to moderate interrupts when possible, they are still needed to drive network processing independent of applications. The receive path of the kernel network stack is executed largely in the interrupt-serving softirq context. Packet events are delivered across kernel threads, and sometimes across CPU cores or even Non-Uniform Memory Access (NUMA) domains because the ksoftirqd threads are decoupled from application threads."

"Resulting from this perceived datedness and inefficiency of the kernel network stack, a recent line of work seeks to abandon the kernel network stack in its entirety. Such work includes library-based network protocol stack implementations that are executed in the context of user-level application processes. Unlike the kernel, however, a userspace application is typically not granted direct access to hardware queues provided by the network controller for security reasons. As a result, they usually leverage specialized provisions made in kernel-mode drivers of NIC allowing ring buffers to be mapped directly into the address space of an application."

"On the other hand, in the context of cloud computing with virtual machines, there is a need for secure direct access to hardware with minimal host overhead, resulting in hardware-based device virtualisation solutions such as the Input-Output Memory Management Unit (IOMMU) \[2\] along with the Virtual Function I/O (VFIO) kernel module, which can expose a Virtual Function (VF) of the NIC to a virtual machine. This approach can also be adapted for user-level networking, where an application, instead of a virtual machine, receives a memory mapping controlled by the IOMMU that grants direct access in both directions (application to hardware and vice-versa)."

"Levels of kernel involvement in network processing can vary even among stacks labelled as user-level. The term kernel-bypass is used to denote minimal involvement of the kernel in the data path, where the application takes complete control of at least a subset of hardware RX/TX queues. This design is used for the majority of high-performance user-level network stacks today. As a result, in most of this work, except when clearly indicated otherwise to highlight the differences, the two terms user-level networking and kernel-bypass networking are used interchangeably."

* 

"A side effect of processing network protocol stacks in userspace is that the user-level pro5 cess must often run in a constant polling loop on dedicated CPU cores. This requirement results from the fact that major operating systems available today provide no mechanism for routing interrupts to specific user-level processes. Instead of hardware interrupts themselves, only their effects1 can be made available to applications. As a result, to receive interrupts in a userspace process necessarily means kernel processing, which kernel-bypass networking by definition cannot rely on. Even with IOMMU, an application process, without at least access to a virtualized ring0 2 , cannot receive interrupts from hardware."

"However, depending on the exact execution model chosen, even with user-level networking, it is possible to designate only a subset of cores to run in polling mode, and to rely on user-level communication for the rest of the application to receive data. Such a model is nevertheless very different from the fundamentally interrupt-based handling in kernel space"

### User-Level Networking Frameworks

##### DPDK

##### PF_RING and Packet Shader

"All PMDs expose a common interface to the rest of DPDK and applications built on top, enabling application code to be agnostic over the specific kernel-bypass mechanism in use. As the name may suggest, most if not all PMDs require polling-mode execution. A polling loop is managed by DPDK on each available core that drives execution of the application. The polling loop scans the RX rings for traffic, and if the result is non-empty, it then hands over control to the application for processing. Applications must, in response, return to the polling loop once any handling logic is complete. In contrast to the default kernel network stack, there is near-perfect coordination between the application and the network stack when running under this polling loop. This relationship comes at the cost of dedicated resource allocation, since typical DPDK applications must be assigned an exclusive set of cores in order to be constantly polling."

##### eXpress Data Path

### User-Level Network Stacks

In this section, two types of stacks based on *DPDK* – userspace ports of kernel stacks like *F-Stack* / *Linux Kernel Library (LKL)*, and complete re-implementations of network stacks such as *Shenango / Caladan* – are introduced as the focus of comparison for this work. Both provide relevant points of reference for different reasons.

Other user-level networking approaches exist, with *Onload* being an example based on AF *XDP* or *ef_vi*, a kernel-bypass mechanism specific to Xilinx NICs. *Seastar* , an asynchronous programming framework for C++, includes a network stack primarily targeting *DPDK*. *mTCP*  can switch among a number of user-level networking backends, including *DPDK* and *PacketShader*’s I/O engine. Some library implementations of network protocol stacks are agnostic of any underlying packet ingestion framework, lwIP being a prominent example. However, none listed above provide or claim levels of source compatibility, performance, or maturity that eclipse those described below.

##### F-Stack and Linux Kernel Library (LKL)

* 

"F-Stack is a port of the FreeBSD network stack to *DPDK*. The project includes the complete source code of the FreeBSD kernel, but replaces all functions pertaining to multithreading, synchronization, and device drivers with empty stubs. Instead, the network stack, along with any application code, is executed within the main polling loop managed by *DPDK*. When network data is retrieved by the polling loop, it is emitted through the FreeBSD network stack, now with all system dependencies removed or replaced. This adaptation is facilitated through a virtual ethernet device (veth) registered with the FreeBSD network stack. After processing, an application-supplied callback will be invoked by *FStack* within the same synchronous execution path, from which application logic can be performed."

#### Shenango / Caladan

"The conventional wisdom is that CPU resources such as cores, caches, and memory bandwidth must be partitioned to achieve performance isolation between tasks. Both the widespread availability of cache partitioning in modern CPUs and the recommended practice of pinning latency-sensitive applications to dedicated cores attest to this belief. In this paper, we show that resource partitioning is neither necessary nor sufficient. Many applications experience bursty request patterns or phased behavior, drastically changing the amount and type of resources they need. Unfortunately, partitioning-based systems fail to react quickly enough to keep up with these changes, resulting in extreme spikes in latency and lost opportunities to increase CPU utilization. Caladan is a new CPU scheduler that can achieve significantly better quality of service (tail latency, throughput, etc.) through a collection of control signals and policies that rely on fast core allocation instead of resource partitioning. Caladan consists of a centralized scheduler core that actively manages resource contention in the memory hierarchy and between hyperthreads, and a kernel module that bypasses the standard Linux Kernel scheduler to support microsecondscale monitoring and placement of tasks. When colocating memcached with a best-effort, garbage-collected workload, Caladan outperforms Parties, a state-of-the-art resource partitioning system, by 11,000×, reducing tail latency from 580 ms to 52 µs during shifts in resource usage while maintaining high CPU utilization." - caladan paper abstr.
